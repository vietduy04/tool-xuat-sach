{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e40087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b94180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "\n",
    "HUB_OVERRIDES = {\n",
    "    # don_vi_khai_thac: chi_nhanh_HUB\n",
    "    \"HUBTAN\": \"BDG\",\n",
    "    \"HUBBHD\": \"BDH\",\n",
    "}\n",
    "\n",
    "RULE_SCHEMA_OVERRIDES = {\n",
    "    \"thoigian_nhapdau\": pl.Time(),\n",
    "    \"thoigian_nhapcuoi\": pl.Time(),\n",
    "    \"thoigian_xuat\": pl.Time(),\n",
    "    \"ngay_xuat\": pl.Int8(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "def load_excel(path: str, **read_options) -> pl.DataFrame:\n",
    "    return pl.read_excel(path, **read_options)\n",
    "\n",
    "def load_with_threads(excel_files: list, **read_options) -> pl.DataFrame:\n",
    "    dfs = []\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = [executor.submit(load_excel, f, **read_options) for f in excel_files]\n",
    "        for future in as_completed(futures):\n",
    "            dfs.append(future.result())\n",
    "\n",
    "    return pl.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper functions ---\n",
    "\n",
    "def import_rule(file, rule_type: str) -> pl.DataFrame:\n",
    "    try:\n",
    "        df = pl.read_excel(file, schema_overrides=RULE_SCHEMA_OVERRIDES)\n",
    "        # Pending validation logic\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Lỗi đọc rule: {e}\")\n",
    "        raise\n",
    "\n",
    "def import_lookup(file) -> pl.DataFrame:\n",
    "    try:\n",
    "        df = pl.read_excel(file)\n",
    "        # Pending validation logic\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Lỗi đọc lookup: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def apply_rule(lf: pl.LazyFrame, rule: pl.LazyFrame, type: str) -> pl.LazyFrame:\n",
    "    try:\n",
    "        # Join keys\n",
    "        join_keys_mapping = {\n",
    "            \"RD\": {\n",
    "                \"left_on\": [\"don_vi_khaithac\", \"ma_buucuc_phat\"],\n",
    "                \"right_on\": [\"don_vi_khai_thac\", \"buu_cuc_phat\"],\n",
    "            },\n",
    "            \"KN\": {\n",
    "                \"left_on\": [\"don_vi_khaithac\", \"chi_nhanh_phat\"],\n",
    "                \"right_on\": [\"don_vi_khai_thac\", \"chi_nhanh_phat\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "        keys = join_keys_mapping[type]\n",
    "\n",
    "        # Join\n",
    "        lf = lf.join(\n",
    "            rule, how=\"left\", left_on=keys[\"left_on\"], right_on=keys[\"right_on\"]\n",
    "        )\n",
    "\n",
    "        # Flag khớp key\n",
    "        lf = lf.with_columns(\n",
    "            pl.col(\"thoigian_nhapdau\").is_not_null().alias(\"_key_matched\")\n",
    "        )\n",
    "\n",
    "        # Lấy thời gian nhập để so sánh\n",
    "        lf = lf.with_columns(pl.col(\"tg_nhap_buucuc\").dt.time().alias(\"_enter_time\"))\n",
    "\n",
    "        # Flag khớp khoảng giờ nhập\n",
    "        lf = lf.with_columns(\n",
    "            pl.when(pl.col(\"_key_matched\"))\n",
    "            .then(\n",
    "                (pl.col(\"_enter_time\") >= pl.col(\"thoigian_nhapdau\"))\n",
    "                & (pl.col(\"_enter_time\") <= pl.col(\"thoigian_nhapcuoi\"))\n",
    "            )\n",
    "            .otherwise(False)\n",
    "            .alias(\"_time_matched\")\n",
    "        )\n",
    "\n",
    "        # Tính deadline (ngày nhập + giờ deadline + ngày offset)\n",
    "        lf = lf.with_columns(\n",
    "            (pl.col(\"thoigian_xuat\") - pl.time(0, 0, 0)).alias(\"_deadline_period\")\n",
    "        )\n",
    "\n",
    "        lf = lf.with_columns(\n",
    "            pl.when(pl.col(\"_time_matched\"))\n",
    "            .then(\n",
    "                pl.col(\"tg_nhap_buucuc\").dt.truncate(\"1d\")  # Ngày nhập tại 00h00\n",
    "                + pl.col(\"_deadline_period\")  # Giờ deadline\n",
    "                + pl.duration(days=pl.col(\"ngay_xuat\"))  # Ngày offset\n",
    "            )\n",
    "            .otherwise(None)\n",
    "            .alias(\"Deadline\")\n",
    "        )\n",
    "\n",
    "        # Gán nhãn:\n",
    "        # - Nếu không tìm thấy cặp key thì rule đang thiếu → Check lại\n",
    "        # - Nếu thấy cặp key, nhưng không có khung thời gian nào hợp lệ → Thiếu config\n",
    "        # - Nếu thời gian lái xe nhận (thời gian xuất kho) <= deadline → Đúng\n",
    "        # - Còn lại là sai hẹn\n",
    "        lf = lf.filter(\n",
    "            (~pl.col(\"_key_matched\"))\n",
    "            | (pl.col(\"_key_matched\") & pl.col(\"_time_matched\"))\n",
    "        ).with_columns(\n",
    "            pl.when(pl.col(\"_key_matched\").not_())\n",
    "            .then(pl.lit(\"Check lại\"))\n",
    "            .when(pl.col(\"_time_matched\").not_())\n",
    "            .then(pl.lit(\"Thiếu config\"))\n",
    "            .when(pl.col(\"tg_laixe_nhan\") <= pl.col(\"Deadline\"))\n",
    "            .then(pl.lit(\"Đúng\"))\n",
    "            .otherwise(pl.lit(\"Sai hẹn\"))\n",
    "            .alias(\"Kết quả\")\n",
    "        )\n",
    "\n",
    "        # Bỏ các dòng không cần thiết\n",
    "        lf = lf.drop(\n",
    "            [\"_key_matched\", \"_time_matched\", \"_deadline_period\", \"_enter_time\"]\n",
    "        )\n",
    "\n",
    "        return lf\n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Lỗi không áp được rule: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be84907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_xuatsach_HUB(raw_files: list, config: dict) -> list[str]:\n",
    "    # Create temporary data directory\n",
    "    tmp_dir = Path(tempfile.mkdtemp())\n",
    "    try:\n",
    "        \n",
    "\n",
    "        raw_format = config[\"raw_format\"]\n",
    "        # output_format = config[\"output_format\"]\n",
    "        output_path = config[\"output_path\"]\n",
    "\n",
    "        # --- Ingesting ---\n",
    "\n",
    "        # Import lookup and rules as lazyframe\n",
    "        rule_rd = import_rule(config[\"rule_rd\"], \"RD\")\n",
    "        lf_rule_rd = rule_rd.lazy()\n",
    "\n",
    "        rule_kn = import_rule(config[\"rule_kn\"], \"KN\")\n",
    "        lf_rule_kn = rule_kn.lazy()\n",
    "\n",
    "        lookup = import_lookup(config[\"lookup\"])\n",
    "        lf_lookup = lookup.lazy()\n",
    "\n",
    "        # Ingest Excel file to csv\n",
    "        if raw_format == \"xlsx\":\n",
    "            ingested = ingest_excel(raw_files)\n",
    "        else:\n",
    "            ingested = pl.scan_csv(raw_files)\n",
    "\n",
    "        # Scan files as lazyframe\n",
    "        lf = ingested.lazy()\n",
    "\n",
    "        # --- Transformations ---\n",
    "\n",
    "        # Thêm cột ngày xuất (phục vụ export)\n",
    "        lf = lf.with_columns(pl.col(\"tg_laixe_nhan\").dt.date().alias(\"_date\"))\n",
    "\n",
    "        # Xác định chi nhánh hiện tại theo đơn vị khai thác\n",
    "        lf = lf.with_columns(\n",
    "            pl.col(\"don_vi_khaithac\").str.slice(3, 3).alias(\"chi_nhanh_HUB\")\n",
    "        )\n",
    "\n",
    "        # Thay thế theo HUB_OVERRIDES\n",
    "        if HUB_OVERRIDES:\n",
    "            expr = pl.col(\"chi_nhanh_HUB\")\n",
    "            for match_value, new_value in HUB_OVERRIDES.items():\n",
    "                expr = (\n",
    "                    pl.when(pl.col(\"don_vi_khaithac\") == match_value)\n",
    "                    .then(pl.lit(new_value))\n",
    "                    .otherwise(expr)\n",
    "                )\n",
    "            lf = lf.with_columns(expr.alias(\"chi_nhanh_HUB\"))\n",
    "\n",
    "        # Xác định chi nhánh phát cũ theo lookup\n",
    "        lf = (\n",
    "            lf.join(\n",
    "                lf_lookup, how=\"left\", left_on=\"ma_buucuc_phat\", right_on=\"ma_buucuc\"\n",
    "            )\n",
    "            .drop(\"chi_nhanh_phat\")\n",
    "            .rename({\"ma_tinh\": \"chi_nhanh_phat\"})\n",
    "        )\n",
    "\n",
    "        # Phân loại đơn rải đích / kết nối\n",
    "        lf = lf.with_columns(\n",
    "            pl.when(pl.col(\"chi_nhanh_HUB\") == pl.col(\"chi_nhanh_phat\"))\n",
    "            .then(pl.lit(\"RD\"))\n",
    "            .otherwise(pl.lit(\"KN\"))\n",
    "            .alias(\"phan_loai\")\n",
    "            .cast(pl.Categorical)\n",
    "        )\n",
    "\n",
    "        # Tìm rule và deadline phù hợp với mỗi đơn\n",
    "        rules = {\"RD\": lf_rule_rd, \"KN\": lf_rule_kn}\n",
    "        outputs = {\"RD\": pl.LazyFrame(), \"KN\": pl.LazyFrame()}\n",
    "\n",
    "        for type in outputs.keys():\n",
    "            filtered = lf.filter(pl.col(\"phan_loai\") == type)\n",
    "            outputs[type] = apply_rule(lf=filtered, rule=rules[type], type=type)\n",
    "\n",
    "        # --- Export ---\n",
    "\n",
    "        fn_map = {\"RD\": \"RaiDich\", \"KN\": \"KetNoi\"}\n",
    "\n",
    "        if output_format == \"csv\":\n",
    "            out = output_path\n",
    "        else:\n",
    "            out = tmp_dir\n",
    "\n",
    "        for type in outputs.keys():\n",
    "            outputs[type].sink_csv(\n",
    "                pl.PartitionByKey(\n",
    "                    base_path=out,\n",
    "                    by=\"_date\",\n",
    "                    file_path=lambda ctx: f\"XuatsachHUB-{fn_map[type]}-{ctx.keys[0].str_value}.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Convert to Excel if required\n",
    "        if output_format == \"xlsx\":\n",
    "            files = [f for f in os.listdir(tmp_dir) if f.endswith(\".csv\")]\n",
    "            export_excel(tmp_dir, files, output_path)\n",
    "\n",
    "        return os.listdir(output_path)\n",
    "\n",
    "    except Exception:\n",
    "        raise\n",
    "    finally:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "\n",
    "\n",
    "def pipeline_xuatsach_TTKT(raw_files: list, config: dict) -> list[str]:  \n",
    "    try:\n",
    "        # --- Load configuration ---\n",
    "        print(\"Starting TTKT pipeline...\")\n",
    "        raw_format = config[\"raw_format\"]\n",
    "        output_format = config[\"output_format\"]\n",
    "        output_path = config[\"output_path\"]\n",
    "    \n",
    "        # --- Ingesting ---\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            # Import rules as lazyframe\n",
    "            print(\"Importing rules...\")\n",
    "            rule = import_rule(config[\"rule_ttkt\"], \"RD\")\n",
    "            lf_rule = rule.lazy()\n",
    "    \n",
    "            # Ingest Excel file to csv\n",
    "            print(\"Importing raw files...\")\n",
    "            if raw_format == \"xlsx\":\n",
    "                ingested = load_with_threads(raw_files, read_options={\"skip_rows\": 1})\n",
    "            else:\n",
    "                ingested = pl.scan_csv(raw_files)\n",
    "\n",
    "            # Scan files as lazyframe\n",
    "            lf = ingested.lazy()\n",
    "\n",
    "            lf = lf.with_columns(\n",
    "                [\n",
    "                    pl.col(\"tg_nhap_buucuc\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    pl.col(\"tg_laixe_nhan\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # --- Transformations ---\n",
    "            print(\"Transforming data...\")\n",
    "\n",
    "            # Tìm rule và deadline phù hợp với mỗi đơn (Tương tự rule rải đích)\n",
    "            lf = apply_rule(lf, rule=lf_rule, type=\"RD\")\n",
    "\n",
    "            # --- Export ---\n",
    "            print(\"Exporting results...\")\n",
    "\n",
    "            timestamp = time.strftime(\"%H%M%S_%d%m%Y\")\n",
    "                    \n",
    "            lf.sink_csv(\n",
    "                os.path.join(output_path, f\"XuatsachTTKT@{timestamp}.csv\"),\n",
    "                datetime_format=\"%Y-%m-%d %H:%M:%S\",\n",
    "                date_format= \"%Y-%m-%d\",\n",
    "                time_format=\"%H:%M:%S\"\n",
    "            )\n",
    "\n",
    "    except Exception:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['raw_format'] = 'xlsx'\n",
    "config['output_format'] = 'csv'\n",
    "config['output_path'] = './output'\n",
    "\n",
    "# config['lookup'] = './data/lookup.xlsx'\n",
    "# config['rule_rd'] = './data/RD.xlsx'\n",
    "# config['rule_kn'] = './data/KN.xlsx'\n",
    "config['rule_ttkt'] = './rule_xs_log_1812.xlsx'\n",
    "\n",
    "raw_files = [os.path.join('./xslog1712', f) for f in os.listdir('./xslog1712')]\n",
    "# raw_files = ['./test.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7108b632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TTKT pipeline...\n",
      "Importing rules...\n",
      "Importing raw files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not determine dtype for column 18, falling back to string\n",
      "Could not determine dtype for column 19, falling back to string\n",
      "Could not determine dtype for column 20, falling back to string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data...\n",
      "Exporting results...\n"
     ]
    }
   ],
   "source": [
    "pipeline_xuatsach_TTKT(\n",
    "    raw_files=raw_files,\n",
    "    config=config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
